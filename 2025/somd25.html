<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="4th Workshop on Scholarly Document Processing">
  <!-- LOGO AND TITLE SIDE-BY-SIDE -->

    <div style="display: flex; align-items: center; justify-content: center; margin-bottom: 20px;">
    <title>5th Workshop on Scholarly Document Processing</title>
  </div>
    <!-- Bootstrap core CSS -->
    <link href="./dist/css/bootstrap.min.css" rel="stylesheet">
  
    <!-- Fira Sans font -->
    <link href="https://fonts.googleapis.com/css?family=Fira+Sans&display=swap" rel="stylesheet">
  
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
  
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
      <![endif]-->
  
    <!-- Custom styles for this template -->
    <link href="styles.css" rel="stylesheet">
  
    <!-- icons -->
    <link rel="stylesheet" href="./font-awesome-4.1.0/css/font-awesome.min.css">

    <!-- jQuery -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
  
  </head>

<body>

  <!-- NAVBAR ================================================== -->

  <div class="navbar-wrapper"></div>
<script src="menu.js" type="text/javascript"></script>

<!-- MAIN CONTENT ============================================= -->

<div class="container marketing navbar-spacing">
<!-- LOGO AND TITLE -->
<div style="text-align: center; margin-bottom: 20px;">
  <img src="images/nfdi_logo.png" alt="SOMD 2025 Logo" style="width:400px; height:auto;">
</div>

  <div class="row featurette">
    <div class="col-md-12">
      <div style="display: flex; align-items: center; justify-content: center; margin-bottom: 20px;">
    <h1 style="margin: 0;">Software Mention Detection (SOMD) 2025</h1>
  <img src="images/somd_logo.png" alt="SOMD 2025 Logo" style="width:100px; height:auto; margin-left: 15px;">
    </div>
      <p>Software plays an essential role in scientific research and is considered one of the crucial entity types in scholarly documents. However, the software is usually not cited formally in academic documents, resulting in various informal software mentions. Automatic identification and disambiguation of software mentions, related attributes, and the purpose of software mentions contributes to the better understanding, accessibility, and reproducibility of research but is a challenging task (<a href="#ref9">Schindler et al., 2021</a>). </p>
      <p>This competition invites participants <a href="https://www.codabench.org/competitions/5840">(Link for Participation)</a> to develop a system that detects software mentions and their attributes as named entities from scholarly texts and classifies the relationships between these entity pairs. The dataset includes sentences from full-text scholarly documents annotated with Named Entities and Relations. It contains various software types, such as Operating Systems or Applications, and attributes like URLs and version numbers.
        This task emphasizes the joint learning of Named Entity Recognition (NER) and Relation Extraction (RE) (<a href="#ref1">Hennen et al., 2024</a> ; <a href="#ref2">Cabot & Navigli, 2021 </a>; <a href="#ref4">Wadden et al., 2019</a>; <a href="#ref5">Ye et al., 2022</a>) to improve computational efficiency and model accuracy, moving away from traditional pipeline approaches (<a href="#ref6">Zeng et al., 2014</a>; <a href="#ref7">Zhang et al., 2017</a>) . Effective integration of NER and RE, as supported by relevant studies, significantly boosts performance (<a href="#ref3">Li & Ji, 2014</a>).
        </p>
    </div>
  </div>

  <h2>Competition Platform and Phases</h2>
  <p>Platform:  Participants will submit their entries on the Codabench platform. Please follow <a href="https://www.codabench.org/competitions/5840/" >this</a> Link to Participate.
    The competition will proceed in two phases:</p>
  <ul>
    <li>Phase I: Participants will develop their models using a training set that aligns with the first test set.</li>
    <li>Phase II: The second test set, scholarly documents  sampled from computer science journals in pubmed central, will test the generalization of the developed systems to out-of-distribution datasets.</li>
  </ul>

  <h2>Dataset</h2>
  <p>We will upload the dataset shortly after the competition begins. </p>

  <h2>Evaluation</h2>
  <p>We evaluate submissions using the F1 score, a metric that reflects the accuracy and precision of the Named Entity Recognition (NER) and Relation Extraction (RE). We will calculate macro-average F1 score using exact match (<a href='#ref8'>Nakayama, 2018</a>) criteria for each of the two test phases. </p>
   
  <h2>Competition Timeline Overview</h2>
  <ul>
    <li>Competition Registration starts on February 24, 2025</li>
    <li>First phase: Dataset release, Train, and Test Data: February 27, 2025</li>
    <li>First phase ends (Submission closes on): March 18, 2025</li>
    <li>Second phase data release: March 18, 2025 </li>
    <li>The competition ends (Phase II submission closed): April 3, 2025</li>
    <li>Paper submission deadlines: April 17, 2025</li>
    <li>Notification of Acceptance: May 1, 2025</li>
    <li>Camera-ready Paper Deadline for Workshop: May 16, 2025.</li>
    <li>Workshop Date: July 21-August 1, 2025</li>
  </ul>

  <h2>Organizers</h2>
  <p>Sharmila Upadhyaya (GESIS Leibniz Institut für Sozialwissenschaften, Germany)</p>
  <p>Frank Krueger (Wismar University of Applied Sciences, Germany)</p>
  <p>Stefan Dietze (GESIS Leibniz Institut für Sozialwissenschaften, Cologne & Heinrich-Heine-University Düsseldorf, Germany)</p>

  <p>For inquiries: <a href="mailto:somd25@googlegroups.com">somd25@googlegroups.com</a>. Join our <a href="https://groups.google.com/g/somd25">Google Group </a> for updates and discussions related to the competition.</p>
  <!-- Funding Section -->
  <section id="funding">
      <h3>Funding</h3>
      <p>This work has received funding through the DFG project NFDI4DS (no. 460234259)</p>
      <p>We wish to thank NFDI4DS for both funding and support. A special thanks goes to all institutions and actors engaging for the association and its goals.</p>
      <p>For more information about NFDI4DS, visit <a href="https://www.nfdi4datascience.de/"> the website </a></p>  
  </section>



    <h3>References</h3>
    <ul>

        <li id="ref1">
            <cite>Hennen, M., Babl, F., & Geierhos, M. (2024).</cite> ITER: Iterative Transformer-based Entity Recognition and Relation Extraction. 11209-11223. 
            <a href="https://doi.org/10.18653/v1/2024.findings-emnlp.655">DOI:10.18653/v1/2024.findings-emnlp.655</a>
        </li>
        <li id="ref2">
            <cite>Huguet Cabot, P.-L., & Navigli, R. (2021).</cite> REBEL: Relation Extraction By End-to-end Language generation. 2370-2381.
            <a href="https://doi.org/10.18653/v1/2021.findings-emnlp.204">DOI:10.18653/v1/2021.findings-emnlp.204</a>
        </li>
        <li id="ref3">
            <cite>Li, Q., & Ji, H. (2014).</cite> Incremental Joint Extraction of Entity Mentions and Relations. 402-412. 
            <a href="https://doi.org/10.3115/v1/P14-1038">DOI:10.3115/v1/P14-1038</a>
        </li>
        <li id="ref4">
            <cite>Wadden, D., Wennberg, U., Luan, Y., & Hajishirzi, H. (2019).</cite> Entity, Relation, and Event Extraction with Contextualized Span Representations. 5783-5788. 
            <a href="https://doi.org/10.18653/v1/D19-1585">DOI:10.18653/v1/D19-1585</a>
        </li>
        <li id="ref5">
            <cite>Ye, D., Lin, Y., Li, P., & Sun, M. (2022).</cite> Packed Levitated Marker for Entity and Relation Extraction. 4904-4917. 
            <a href="https://doi.org/10.18653/v1/2022.acl-long.337">DOI:10.18653/v1/2022.acl-long.337</a>
        </li>
        <li id="ref6">
            <cite>Zeng, D., Liu, K., Lai, S., Zhou, G., & Zhao, J. (2014).</cite> Relation Classification via Convolutional Deep Neural Network.
            <a href="https://aclanthology.org/C14-1220/">ACL Anthology</a>
        </li>
        <li id="ref7">
            <cite>Zhang, Y., Zhong, V., Chen, D., Angeli, G., & Manning, C. D. (2017).</cite> Position-aware Attention and Supervised Data Improve Slot Filling. 35-45. 
            <a href="https://doi.org/10.18653/v1/D17-1004">DOI:10.18653/v1/D17-1004</a>
        </li>
      <li id="ref8">
           <cite>Nakayama, H. (2018).</cite> seqeval: A Python framework for sequence labeling evaluation.
<a href="https://github.com/chakki-works/seqeval">Software available from https://github.com/chakki-works/seqeval</a>

        </li>
      <li id="ref9">
        <cite>Schindler, D., Bensmann, F., Dietze, S., & Krüger, F. (2021).</cite> SoMeSci- A 5 Star Open Data Gold Standard Knowledge Graph of Software Mentions in Scientific Articles. 4574–4583. 
        <a href="https://doi.org/10.1145/3459637.3482017">DOI:10.1145/3459637.3482017</a>
    </li>

    </ul>

  
    <!-- FOOTER ========================================== -->



    <hr><br />
  
    <footer>
      <div class="footer-wrapper">
        <div class="footer-left">
          <p>Contact: <a href="mailto:sdproc2025@googlegroups.com">sdproc2025@googlegroups.com</a></p>
          <p>Sign up for updates: <a href="https://groups.google.com/g/sdproc-updates">https://groups.google.com/g/sdproc-updates</a></p>
          <p>Follow us: <a href="https://twitter.com/SDPWorkshop">https://twitter.com/SDPWorkshop</a></p>
        </div>
        <div class="footer-right">
          <a href="#">Back to top</a>
        </div>
    </footer>
  
  </div>

  <!-- Bootstrap core JavaScript ================================================== -->
  <script src="./dist/js/bootstrap.min.js"></script>

</body>

</html>

<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="5th Workshop on Scholarly Document Processing">

  <title>5th Workshop on Scholarly Document Processing: Shared Tasks</title>

  <!-- Bootstrap core CSS -->
  <link href="./dist/css/bootstrap.min.css" rel="stylesheet">

  <!-- Fira Sans font -->
  <link href="https://fonts.googleapis.com/css?family=Fira+Sans&display=swap" rel="stylesheet">

  <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->

  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

  <!-- Custom styles for this template -->
  <link href="styles.css" rel="stylesheet">

  <!-- icons -->
  <link rel="stylesheet" href="./font-awesome-4.1.0/css/font-awesome.min.css">

  <!-- jQuery -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>

</head>

<body>

  <!-- NAVBAR ================================================== -->

  <div class="navbar-wrapper"></div>
  <script src="menu.js" type="text/javascript"></script>

  <!-- MAIN CONTENT ============================================= -->

  <div class="container marketing navbar-spacing">

    <div class="row">
      <div class="col-md-12">

        <!-- CFP INTRODUCTION ================================================== -->


        <h1>Shared Tasks</h1>

      
        <hr class="featurette-divider">

        <h2>Quick links</h2>

        <ul>
          <li>
            <a href="#dagpap25">DAGPAP25: Detecting automatically-generated papers</h2></a>
          </li>
        <li>
            <a href="#context25">Context25: Contextualizing Scientific Figures and Tables</h2></a>
          </li>
          <li>
            <a href="#SciVQA">SciVQA: Scientific Visual Question Answering</h2></a>
          </li>
          <li>
            <a href="#ClimateCheck">ClimateCheck: Scientific Fact-checking of Social Media Posts on Climate Change</h2></a>
          </li>
          <li>
            <a href="#somd">SOMD25: Software Mention Detection in Scholarly Publications</h2></a>
          </li>
        </ul>

      

        <hr class="featurette-divider">

        <!-- DAGPap ========================================================= -->

        <h2 id="dagpap25">DAGPap25: Detecting automatically generated scientific papers</h2>

        <p>
          A big problem with the ubiquity of Generative AI is that it has now become very easy to generate fake scientific papers. This can erode public trust in science and attack the foundations of science: are we standing on the shoulders of robots? The Detecting Automatically Generated Papers (DAGPAP) competition aims to encourage the development of robust, reliable AI-generated scientific text detection systems, utilizing a diverse dataset and varied machine learning models in a number of scientific domains. 
        </p> 
		
		<h3>Organizers</h3>

        <p><a href="https://www.linkedin.com/in/savvas-chamezopoulos-a567038a">Savvas Chamezopoulos</a>, Elsevier</p>


        <p><a href="">Dan Li</a></p>

        <p><a href="https://www.elsevier.com/connect/contributors/anita-de-waard-phd">Anita de Waard</a>, Elsevier</p>
      <!--   <p>
          <!-- You are invited to participate in the shared task "DAGPap24: Detecting automatically generated scientific papers" collocated with the <a href="https://sdproc.org/2024/">4th Workshop on 
          Scholarly Document Processing</a> (SDP 2024) to be held at <a href="https://2024.aclweb.org/">ACL 2024</a>. The competition will be held on <a href="https://www.codabench.org/">CodaBench</a>, 
          launching on April 2nd, 2024. Participants are also invited to submit papers describing their findings.
        </p>

        <p>
          Papers must follow the ACL format and conform to the ACL 2024 Submission Guidelines. Paper submission has to be done through <a href="https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/SDProc">OpenReview.net</a>:
        </p>

        <ul>
          <li><a href="https://www.codabench.org/competitions/2431/">Leaderboard (CodaBench)</a></li>
          <li><a href="https://sdproc.org/2024/sharedtasks.html#dagpap">Website</a></li>
          <li><a href="http://tinyurl.com/sdpproc">Submission site</a> (OpenReview.net)</li>
<!--           <li>Openreview: https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/SDProc</li> -->
          <!-- <li>Competition dates: April 2nd &mdash; April 30th, 2024</li>
          <li>Paper submission deadline: May <s>17</s> 31th, 2024</li>
        </ul>

        <h3>Monetary prizes</h3>

        <p>We offer the following monetary prizes for the winners of the shared task:</p>

        <ul>
          <li>1st place &mdash; $3000</li>
          <li>2nd place &mdash; $1200</li>
          <li>3rd place &mdash; $800</li>
        </ul>

        <p>
          The winners will be defined based on the corresponding CodaBench competition (to be launched on April 2nd, 2024).
          Additional conditions are the reproducibility of the solution and a technical report submitted to the workshop. 
          </p>

        <h3>Call for Research Papers</h3>

        <p>A big problem with the ubiquity of Generative AI is that it has now become very easy to generate fake scientific papers. This can erode public trust in science and attack the foundations of science: are we standing on the shoulders of robots? The Detecting Automatically Generated Papers (DAGPap) competition aims to encourage the development of robust, reliable AI-generated scientific text detection systems, utilizing a diverse dataset and varied machine learning models in a number of scientific domains.</p>

        <p>Building on top of a <a href="https://www.kaggle.com/competitions/detecting-generated-scientific-papers">similar competition</a> held in 2022, we are now looking into full texts and a more fine-grained detection of LLM-generated scientific content, when artificial content might be interspersed with human-generated one.</p>

        <p>Participants are invited to submit papers describing their findings during the competition.</p>

        <h4>Topics of Interest</h4>

        <p>We are not only interested in seeing technical reports describing competitors' approaches to solving the Shared Task but also invite submissions on related topics:</p>

        <ul>
          <li>Detection of LLM-generated texts</li>
          <li>Robustness of LLM-detectors to data drift</li>
          <li>Specifics of LLM-detectors in the scientific domain</li>
          <li>Explainability of LLM detection</li>
        </ul>

        <p>For an even broader range of topics, please check out the <a href="https://sdproc.org/2024/cfp.html#topics">CFP for the Scholarly Document Processing workshop SDP 2024</a>.</p>

        <h3>Submission Information</h3>

        <p>Authors are invited to submit full and short papers with unpublished, original work. Submissions will be subject to a double-blind peer-review process. Accepted papers will be presented by the authors at the workshop either as a talk or a poster. All accepted papers will be published in the workshop proceedings (proceedings from previous years can be found <a href="https://aclanthology.org/venues/sdp/">here</a>).</p>

        <p>The submissions must be in PDF format and anonymized for review. All submissions must be written in English and follow the ACL 2024 formatting requirements:</p>

        <p>
          <strong>Long paper submissions:</strong> up to 8 pages of content, plus unlimited references.</br>
          <strong>Short paper submissions:</strong> up to 4 pages of content, plus unlimited references.
        </p>

        <p><strong>Paper submission Website:</strong> Paper submission has to be done through <a href="https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/SDProc">OpenReview.net</a>.</p>

        <p>Final versions of accepted papers will be allowed 1 additional page of content so that reviewer comments can be taken into account.</p>

        <h4>Important Dates (Shared Task)</h3>

        <ul>
          <li>Competition launch: April 2nd (Tuesday), 2024</li>
          <li>Development phase: April 2nd - April 28th, 2024</li>
          <li>Final phase: April 29th - April 30th, 2024</li>
          <li>Competition end: April 30th (Tuesday), 2024</li>
          <li>Solutions sharing deadline: May 7th (Tuesday), 2024</li>
          <li>Winners announcement: May 14th (Tuesday), 2024</li>
          <li>Paper submission deadline: May <s>17</s> 31th, (Friday), 2024</li>
          <li>Notification of acceptance: June 28th, 2024</li>
          <li>Camera-ready paper due: July 5th (Friday), 2024</li>
          <li>Workshop dates: August 15th – August 16th, 2024</li>
        </ul>
        
        <h3>Contact</h3>

        <p>For any other questions about the competition, paper submission, the workshop, etc. please contact 
          <a href="mailto:dagpap2024@googlegroups.com">dagpap2024@googlegroups.com</a>.</p>

        <h3>Organizers</h3>

        <p><a href="https://www.linkedin.com/in/savvas-chamezopoulos-a567038a">Savvas Chamezopoulos</a>, Elsevier</p>


        <p><a href="https://yorko.github.io/">Yury Kashnitsky</a>, Elsevier</p>

        <p><a href="https://www.elsevier.com/connect/contributors/anita-de-waard-phd">Anita de Waard</a>, Elsevier</p>

        <!-- <p><a href="https://www.irit.fr/~Guillaume.Cabanac/">Guillaume  Cabanac</a>, University of Toulouse</p> -->

        <!-- <p><a href="https://membres-lig.imag.fr/labbe/">Cyrill Labb&eacute;</a>, Universit&eacute; Grenoble</p> -->

        <!-- <p><a href="https://yandex.com/">Domenic Rosati</a>, scite.ai</p>

        <!-- <p><a href="https://www.linkedin.com/in/georgetsatsaronis/?originalSubdomain=nl">Georgios Tsatsaronis</a>, Elsevier</p> -->

        <!-- <p><a href="https://www.linkedin.com/in/catriona-fennell-57871823/">Catriona Fennell</a>, Elsevier</p> -->

        <!-- <p><a href="https://dasha.tech">Drahomira Herrmannova</a>, Elsevier</p>

        <!-- ========================================================= -->

        <hr class="featurette-divider">

        <h2 id="context25">Context25: Contextualizing Scientific Figures and Tables </h2>

        <p>
        You are invited to participate in the shared task “Context25: Evidence and Grounding Context Identification for Scientific Claims” collocated with the 5th Workshop on Scholarly Document Processing (SDP 2025) to be held at ACL 2025. Participants of the competition are also invited to submit papers describing their findings.  
      </p> 
	  
	     <p>
          Interpreting scientific claims in the context of empirical findings is a valuable practice, yet extremely time-consuming for researchers. Such interpretation of scientific claims requires identifying key results that provide supporting evidence from research papers, and contextualizing these results with associated methodological details (e.g., measures, sample, etc.). In this shared task, we are interested in automating identification of key results (or evidence) as well as additional grounding context to make claim interpretation more efficient. 
        </p>
		
		         <h3>Organizers</h3>

        <p><a href="">Joel Chan (University of Maryland)</a></p>
        <p><a href="">Matthew Akamatsu (University of Washington)</a></p>
        <p><a href="">Aakanksha Naik (Allen Institute for AI)</a></p>

       <!-- <p>
        All papers must follow the ACL format and conform to the ACL 2024 Submission Guidelines. Papers must be submitted via <a href="https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/SDProc">openreview</a>.
        </p>
     

        <p>
          Context24 will have two tracks:
        </p>

        <p>
          <h4>Track 1: Evidence Identification</h4>
          Given a scientific claim and a relevant research paper, identify key figures or tables from the paper that provide supporting evidence for the claim.
        </p>

        <p>
          <h4>Track 2: Grounding Context Identification</h4>
          Given a scientific claim and a relevant research paper, identify all grounding context from the paper discussing methodological details of the experiment that resulted in this claim. This grounding context is typically dispersed throughout the full-text, often far from where the supporting evidence is presented and can include figures, tables or text snippets. 
        </p>

        <h4 style="color: red">The testing phase has now started!</h4> 
        <p> Test data (without labels) is available in our shared task repository: <a href="https://github.com/oasisresearchlab/context24">https://github.com/oasisresearchlab/context24</a>. Submission instructions:</p>
        <ul>
          <li>Submissions will be accepted on our evalAI portal: <a href="https://eval.ai/web/challenges/challenge-page/2306/overview">https://eval.ai/web/challenges/challenge-page/2306/overview</a>.</li>
          <li>For each task, you can make up to 5 submissions per day.</li>
          <li>You will be limited to 50 submissions per task over the duration of the competition.</li>
          <li>Submissions will be accepted until 5 pm PST on June 6.</li>
          <li>If you run into issues with submission, please reach out to aakankshan@allenai.org or raise an issue in the shared task repository.</li>
          </ul>


        <h3>Important Links</h3>
        <ul>
          <li><a href=" https://github.com/oasisresearchlab/context24">Dataset</a></li>
          <li><a href="context24sharedtask@googlegroups.com">Google Group</a></li>
          <li><a href="http://tinyurl.com/sdpproc">Submission site</a> (OpenReview.net)</li>
          <li>Paper submission deadline: June 17th, 2024</li>
        </ul>


        <h3>Important Dates (Shared Task)</h3>

          <ul>
            <li>	Training set release: April 11th (Thursday), 2024 </li>
            <li>Test set release: May 24th (Friday), 2024</li>
            <li>Result announcement: May 31st (Friday), 2024 </li>
            <li>Paper submission deadline: June 17th (Monday), 2024</li>
            <li>Notification of acceptance: June 28th (Friday), 2024 </li>
            <li>Camera-ready paper due: July 8th (Monday), 2024 </li>
            <li>Workshop dates: August 15th–16th, 2024 </li>
          </ul> 

 -->

        <hr class="featurette-divider">
		
<!-- start SciVQA-->
	
	<h2 id="SciVQA">SciVQA: Scientific Visual Question Answering </h2>

       <p>
        Scholarly articles convey valuable information not only through unstructured text but also via (semi-)structured figures such as charts and diagrams. Automatically interpreting the semantics of knowledge encoded in these figures can be beneficial for downstream tasks such as question answering (QA). In the SciVQA challenge, the participants will develop multimodal systems capable of efficiently processing both visual (i.e., addressing attributes such as colour, shape, size, etc.) and non-visual QA pairs based on images of scientific figures and their captions.   
      </p> 

        <h3>Organizers</h3>

        <p><a href="">Ekaterina Borisova</a></p>
        <p><a href="">Georg Rehm</a></p>
    
	
        <hr class="featurette-divider">
		
		
<!-- start ClimateCheck-->	
		
			<h2 id="ClimateCheck">Scientific Fact-checking of Social Media Posts on Climate Change (ClimateCheck) </h2>

       <p>
        The ClimateCheck shared task focuses on fact-checking claims from social media about climate change against peer-reviewed scholarly articles. Participants will retrieve relevant publications from a corpus of 400,000 climate research articles and classify each abstract as supporting, refuting, or not having enough information about the claim. Training data will include human-annotated claim-publication pairs, and the evaluation will combine nDCG@K and Bpref for retrieval and F1 score for classification. The task aims to develop models that link social media claims to scientific evidence, promoting informed and evidence-based discussions on climate change.  
      </p> 

        <h3>Organizers</h3>

        <p><a href="">Raia Abu Ahmad</a></p>
        <p><a href="">Georg Rehm</a></p>
    
	
        <hr class="featurette-divider">
		
		
<!-- start somd-->	
		
			<h2 id="somd">Software Mention Detection in Scholarly Publications (SOMD 25) </h2>

       <p>
        Software plays an essential role in computational research methods and is considered one of the crucial entities in scholarly documents. However, software mentions are not always cited in academic documents, resulting in various informal mentions of software across a paper. Automatic identification of such software mention contributes to the better understanding, accessibility, and reproducibility of the research work. In addition to the mention of software, to understand the research context, it is necessary to understand the purpose of a software mention and its attributes, making software mention detection a comprehensive task. <br>
		We are extending our first iteration of the shared task <a href="https://nfdi4ds.github.io/nslp2024/docs/somd_shared_task.html">SOMD 2024</a> with new challenges. In addition to information extraction techniques, our extended focus would be on: Joint Named Entity and relation classification techniques and performance improvement for long-tail entity types or weak entities.   
      </p> 

        <h3>Organizers</h3>

        <p><a href="">Sharmila Upadhyaya</a></p>
        <p><a href="">Frank Krueger</a></p>
		<p><a href="">Stefan Dietze</a></p>
		
    
	
        <hr class="featurette-divider">
  

      </div>
    </div>

    <!-- FOOTER ========================================== -->

    <hr><br />

    <footer>
      <div class="footer-wrapper">
        <div class="footer-left">
          <p>Contact: <a href="mailto:sdproc2025@googlegroups.com">sdproc2025@googlegroups.com</a></p>
          <p>Sign up for updates: <a href="https://groups.google.com/g/sdproc-updates">https://groups.google.com/g/sdproc-updates</a></p>
          <p>Follow us: <a href="https://twitter.com/SDPWorkshop">https://twitter.com/SDPWorkshop</a></p>
        </div>
        <div class="footer-right">
          <a href="#">Back to top</a>
        </div>
    </footer>

  </div>

  <!-- Bootstrap core JavaScript ================================================== -->
  <script src="./dist/js/bootstrap.min.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</body>

</html>

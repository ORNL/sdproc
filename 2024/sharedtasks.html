<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="4th Workshop on Scholarly Document Processing">

  <title>4th Workshop on Scholarly Document Processing</title>

  <!-- Bootstrap core CSS -->
  <link href="./dist/css/bootstrap.min.css" rel="stylesheet">

  <!-- Fira Sans font -->
  <link href="https://fonts.googleapis.com/css?family=Fira+Sans&display=swap" rel="stylesheet">

  <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->

  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

  <!-- Custom styles for this template -->
  <link href="styles.css" rel="stylesheet">

  <!-- icons -->
  <link rel="stylesheet" href="./font-awesome-4.1.0/css/font-awesome.min.css">

  <!-- jQuery -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>

</head>

<body>

  <!-- NAVBAR ================================================== -->

  <div class="navbar-wrapper"></div>
  <script src="menu.js" type="text/javascript"></script>

  <!-- MAIN CONTENT ============================================= -->

  <div class="container marketing navbar-spacing">

    <div class="row">
      <div class="col-md-12">

        <!-- CFP INTRODUCTION ================================================== -->

        <!-- <h1>The 6<sup>th</sup> Computational Linguistics Scientific Document Summarization Shared
          Task (CL-SciSumm 2020)</h1> -->

        <h1>Shared Tasks</h1>

        <!-- <p>
          <a href="https://docs.google.com/forms/d/e/1FAIpQLScfHzByrog-k299qBuCp3SbPWcb905_kmOWMvHpDH57VLpVrg/viewform"><button type="button" class="btn btn-primary">Shared Tasks Registration</button></a>
        </p>

        <hr class="featurette-divider"> -->

        <h2>Quick links</h2>

        <ul>
         <!--  <li>
            <a href="#sapr">SAPR23: Systems for Semi-Automated Peer Review</a>
          </li>
          <li>
            <a href="#sacl">SACL23: Structured Abstracts for Computational Linguistics</a>
          </li> -->
          <li>
            <a href="#dagpap">DAGPAP24: Detecting automatically-generated papers</h2></a>
          </li>
       <!--    <li>
            <a href="#mup">MuP23: Multi Perspective Scientific Document Summarization</a>
          </li>
          <li>
            <a href="#svident">SV-Ident23: Survey Variable Identification in Social Science</a>
          </li>
          <li>
            <a href="#graph">Scholarly Knowledge Graph Generation</a>
          </li>
          <li>
            <a href="#ar">NLP for Augmented Reading Interfaces</a>
          </li>
          <li>
            <a href="#SciCompare">SciCompare</a>
          </li> -->
           <li>
            <a href="#context24">Context24: Contextualizing Scientific Figures and Tables</h2></a>
          </li>
        </ul>

       

        <!-- SAPR23 ========================================================= -->

       <!-- <h2 id="sapr">SAPR23: Systems for Semi-Automated Peer Review</a></h2>

        <p>
          This shared task proposes a challenge to explore developing methods for the semiautomated peer review of future workshops in computational linguistics (and possibly, other domains). The challenge asks for concrete proposals on how such semi-automated peer review can be conducted and assessed. In particular, the shared task is looking for vision or technical papers that propose systems of semi-automated peer reviews for papers submitted to the next SDP Workshop. There is no formal evaluation of this task, but all relevant proposals will be shared and discussed during the SDP workshop in a special session devoted to Structured Abstracts in Computational Linguistics.
        </p>

        <p>
          <!-- Details about data access, task evaluation, and more are available <a href="https://github.com/allenai/mslr-shared-task">here</a>. -->
       

    
          <!-- Please join our <a href="https://groups.google.com/g/mslr-info">mailing list</a> to receive updates or email <a href="mailto:lucyw@allenai.org">lucyw@allenai.org</a> to be added to our Slack workspace. -->
       

        <!-- <ol class="refs" id="refs-sapr">
          <li>Anita de Waard and Tirthankar Ghosal. "<a href="https://aclanthology.org/2021.emnlp-main.594/">MS2: A Dataset for Multi-Document Summarization of Medical Studies</a>." EMNLP (2021).</li>
          <li>Byron C. Wallace, Sayantani Saha, Frank Soboczenski, and Iain James Marshall. (2020). "<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8378607/">Generating (factual?) narrative summaries of RCTs: Experiments with neural multi-document summarization</a>." AMIA Annual Symposium.</li>
        </ol> -->

       <!-- <h3>Organizers</h3>

        <p><a href="https://www.elsevier.com/connect/contributors/anita-de-waard-phd">Anita de Waard</a>, Elsevier</p>

        <p><a href="https://elitr.eu/tirthankar-ghosal/">Tirthankar Ghosal</a>, Charles University, Czech Republic</p>


        <!-- <p>Please email <a href="mailto:mslr-organizers@googlegroups.com">mslr-organizers@googlegroups.com</a> to contact the organizers.</p> -->

        <!-- <h3>Contact</h3> -->

        <!-- <p>Please contact <a href="mailto:shmueli@il.ibm.com">shmueli@il.ibm.com</a> and <a href="mailto:guyf@il.ibm.com">guyf@il.ibm.com</a> with questions about this shared task.</p> -->

      

        <!-- SAPR23 ========================================================= -->

    <!--    <h2 id="sacl">SACL23: Structured Abstracts for Computational Linguistics</a></h2>

        <p>
          Structured digital abstracts, which replace a free-form abstract by a summary of the traditional elements of a research paper (introduction, methods, results, discussion) have been shown to communicate research more effectively than traditional abstracts, at least in the life sciences. Structured abstracts also offer a useful format to support computational tasks such as summarization, argument extraction and the like. Can they improve the scholarly communication in computational linguistics, as well? For this shared task, the community is asked to propose a format for structured abstracts for computational linguistics. We would like to see proposals that are easy to implement in a variety of authoring environments, that are straightforward to understand, and that represent the key knowledge elements found in computational linguistics papers.
        </p>

        <p>
          <!-- Details about data access, task evaluation, and more are available <a href="https://github.com/allenai/mslr-shared-task">here</a>. -->
    

  
          <!-- Please join our <a href="https://groups.google.com/g/mslr-info">mailing list</a> to receive updates or email <a href="mailto:lucyw@allenai.org">lucyw@allenai.org</a> to be added to our Slack workspace. -->
   

        <!-- <ol class="refs" id="refs-sapr">
          <li>Anita de Waard and Tirthankar Ghosal. "<a href="https://aclanthology.org/2021.emnlp-main.594/">MS2: A Dataset for Multi-Document Summarization of Medical Studies</a>." EMNLP (2021).</li>
          <li>Byron C. Wallace, Sayantani Saha, Frank Soboczenski, and Iain James Marshall. (2020). "<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8378607/">Generating (factual?) narrative summaries of RCTs: Experiments with neural multi-document summarization</a>." AMIA Annual Symposium.</li>
        </ol> -->

     <!--   <h3>Organizers</h3>

        <p><a href="https://www.elsevier.com/connect/contributors/anita-de-waard-phd">Anita de Waard</a>, Elsevier</p>

        <p><a href="">Khalid Al-Khatib</a></p>

        <p><a href="">Iryna Gurevych</a></p>

        <p><a href="">Ilia Kuznetsov</a></p>

        <p><a href="">Davide Ceolin</a></p>


        <!-- <p>Please email <a href="mailto:mslr-organizers@googlegroups.com">mslr-organizers@googlegroups.com</a> to contact the organizers.</p> -->

        <!-- <h3>Contact</h3> -->

        <!-- <p>Please contact <a href="mailto:shmueli@il.ibm.com">shmueli@il.ibm.com</a> and <a href="mailto:guyf@il.ibm.com">guyf@il.ibm.com</a> with questions about this shared task.</p> -->

        <hr class="featurette-divider">

        <!-- DAGPap ========================================================= -->

        <h2 id="dagpap">DAGPap24: Detecting automatically generated scientific papers</h2>
<!-- 
        <p>
          A big problem with the ubiquity of Generative AI is that it has now become very easy to generate fake scientific papers. This can erode public trust in science and attack the foundations of science: are we standing on the shoulders of robots? The Detecting Automatically Generated Papers (DAGPAP) competition aims to encourage the development of robust, reliable AI-generated scientific text detection systems, utilizing a diverse dataset and varied machine learning models in a number of scientific domains. 
        </p> -->
        <p>
          You are invited to participate in the shared task "DAGPap24: Detecting automatically generated scientific papers" collocated with the <a href="https://sdproc.org/2024/">4th Workshop on 
          Scholarly Document Processing</a> (SDP 2024) to be held at <a href="https://2024.aclweb.org/">ACL 2024</a>. The competition will be held on <a href="https://www.codabench.org/">CodaBench</a>, 
          launching on April 2nd, 2024. Participants are also invited to submit papers describing their findings.
        </p>

        <p>
          Papers must follow the ACL format and conform to the ACL 2024 Submission Guidelines. Paper submission has to be done through <a href="https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/SDProc">OpenReview.net</a>:
        </p>

        <ul>
          <li><a href="https://www.codabench.org/competitions/2431/">Leaderboard (CodaBench)</a></li>
          <li><a href="https://sdproc.org/2024/sharedtasks.html#dagpap">Website</a></li>
          <li><a href="http://tinyurl.com/sdpproc">Submission site</a> (OpenReview.net)</li>
<!--           <li>Openreview: https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/SDProc</li> -->
          <li>Competition dates: April 2nd &mdash; April 30th, 2024</li>
          <li>Paper submission deadline: May <s>17</s> 31th, 2024</li>
        </ul>

        <h3>Monetary prizes</h3>

        <p>We offer the following monetary prizes for the winners of the shared task:</p>

        <ul>
          <li>1st place &mdash; $3000</li>
          <li>2nd place &mdash; $1200</li>
          <li>3rd place &mdash; $800</li>
        </ul>

        <p>
          The winners will be defined based on the corresponding CodaBench competition (to be launched on April 2nd, 2024).
          Additional conditions are the reproducibility of the solution and a technical report submitted to the workshop. 
          </p>

        <h3>Call for Research Papers</h3>

        <p>A big problem with the ubiquity of Generative AI is that it has now become very easy to generate fake scientific papers. This can erode public trust in science and attack the foundations of science: are we standing on the shoulders of robots? The Detecting Automatically Generated Papers (DAGPap) competition aims to encourage the development of robust, reliable AI-generated scientific text detection systems, utilizing a diverse dataset and varied machine learning models in a number of scientific domains.</p>

        <p>Building on top of a <a href="https://www.kaggle.com/competitions/detecting-generated-scientific-papers">similar competition</a> held in 2022, we are now looking into full texts and a more fine-grained detection of LLM-generated scientific content, when artificial content might be interspersed with human-generated one.</p>

        <p>Participants are invited to submit papers describing their findings during the competition.</p>

        <h4>Topics of Interest</h4>

        <p>We are not only interested in seeing technical reports describing competitors' approaches to solving the Shared Task but also invite submissions on related topics:</p>

        <ul>
          <li>Detection of LLM-generated texts</li>
          <li>Robustness of LLM-detectors to data drift</li>
          <li>Specifics of LLM-detectors in the scientific domain</li>
          <li>Explainability of LLM detection</li>
        </ul>

        <p>For an even broader range of topics, please check out the <a href="https://sdproc.org/2024/cfp.html#topics">CFP for the Scholarly Document Processing workshop SDP 2024</a>.</p>

        <h3>Submission Information</h3>

        <p>Authors are invited to submit full and short papers with unpublished, original work. Submissions will be subject to a double-blind peer-review process. Accepted papers will be presented by the authors at the workshop either as a talk or a poster. All accepted papers will be published in the workshop proceedings (proceedings from previous years can be found <a href="https://aclanthology.org/venues/sdp/">here</a>).</p>

        <p>The submissions must be in PDF format and anonymized for review. All submissions must be written in English and follow the ACL 2024 formatting requirements:</p>

        <p>
          <strong>Long paper submissions:</strong> up to 8 pages of content, plus unlimited references.</br>
          <strong>Short paper submissions:</strong> up to 4 pages of content, plus unlimited references.
        </p>

        <p><strong>Paper submission Website:</strong> Paper submission has to be done through <a href="https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/SDProc">OpenReview.net</a>.</p>

        <p>Final versions of accepted papers will be allowed 1 additional page of content so that reviewer comments can be taken into account.</p>

        <h4>Important Dates (Shared Task)</h3>

        <ul>
          <li>Competition launch: April 2nd (Tuesday), 2024</li>
          <li>Development phase: April 2nd - April 28th, 2024</li>
          <li>Final phase: April 29th - April 30th, 2024</li>
          <li>Competition end: April 30th (Tuesday), 2024</li>
          <li>Solutions sharing deadline: May 7th (Tuesday), 2024</li>
          <li>Winners announcement: May 14th (Tuesday), 2024</li>
          <li>Paper submission deadline: May <s>17</s> 31th, (Friday), 2024</li>
          <li>Notification of acceptance: June 17th (Monday), 2024</li>
          <li>Camera-ready paper due: July 1st (Monday), 2024</li>
          <li>Workshop dates: August 15th – August 16th, 2024</li>
        </ul>
        
        <h3>Contact</h3>

        <p>For any other questions about the competition, paper submission, the workshop, etc. please contact 
          <a href="mailto:dagpap2024@googlegroups.com">dagpap2024@googlegroups.com</a>.</p>

        <h3>Organizers</h3>

        <p><a href="https://www.linkedin.com/in/savvas-chamezopoulos-a567038a">Savvas Chamezopoulos</a>, Elsevier</p>


        <p><a href="https://yorko.github.io/">Yury Kashnitsky</a>, Elsevier</p>

        <p><a href="https://www.elsevier.com/connect/contributors/anita-de-waard-phd">Anita de Waard</a>, Elsevier</p>

        <!-- <p><a href="https://www.irit.fr/~Guillaume.Cabanac/">Guillaume  Cabanac</a>, University of Toulouse</p> -->

        <!-- <p><a href="https://membres-lig.imag.fr/labbe/">Cyrill Labb&eacute;</a>, Universit&eacute; Grenoble</p> -->

        <p><a href="https://yandex.com/">Domenic Rosati</a>, scite.ai</p>

        <!-- <p><a href="https://www.linkedin.com/in/georgetsatsaronis/?originalSubdomain=nl">Georgios Tsatsaronis</a>, Elsevier</p> -->

        <!-- <p><a href="https://www.linkedin.com/in/catriona-fennell-57871823/">Catriona Fennell</a>, Elsevier</p> -->

        <p><a href="https://dasha.tech">Drahomira Herrmannova</a>, Elsevier</p>

        <!-- ========================================================= -->

        <hr class="featurette-divider">

        <h2 id="context24">Context24: Contextualizing Scientific Figures and Tables </h2>

        <p>
        You are invited to participate in the shared task “Context24: Evidence and Grounding Context Identification for Scientific Claims” collocated with the 4th Workshop on Scholarly Document Processing (SDP 2024) to be held at ACL 2024. Participants of the competition are also invited to submit papers describing their findings.  
      </p>

        <p>
        All papers must follow the ACL format and conform to the ACL 2024 Submission Guidelines. Papers must be submitted via <a href="https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/SDProc">openreview</a>.
        </p>
        <p>
          Interpreting scientific claims in the context of empirical findings is a valuable practice, yet extremely time-consuming for researchers. Such interpretation of scientific claims requires identifying key results that provide supporting evidence from research papers, and contextualizing these results with associated methodological details (e.g., measures, sample, etc.). In this shared task, we are interested in automating identification of key results (or evidence) as well as additional grounding context to make claim interpretation more efficient. 
        </p>

        <p>
          Context24 will have two tracks:
        </p>

        <p>
          <h4>Track 1: Evidence Identification</h4>
          Given a scientific claim and a relevant research paper, identify key figures or tables from the paper that provide supporting evidence for the claim.
        </p>

        <p>
          <h4>Track 2: Grounding Context Identification</h4>
          Given a scientific claim and a relevant research paper, identify all grounding context from the paper discussing methodological details of the experiment that resulted in this claim. This grounding context is typically dispersed throughout the full-text, often far from where the supporting evidence is presented and can include figures, tables or text snippets. 
        </p>


        <h3>Important Links</h3>
        <ul>
          <li><a href=" https://github.com/oasisresearchlab/context24">Dataset</a></li>
          <li><a href="context24sharedtask@googlegroups.com">Google Group</a></li>
          <li><a href="http://tinyurl.com/sdpproc">Submission site</a> (OpenReview.net)</li>
          <li>Paper submission deadline: June 17th, 2024</li>
        </ul>


        <h3>Important Dates (Shared Task)</h3>

          <ul>
            <li>	Training set release: April 11th (Thursday), 2024 </li>
            <li>Test set release: May 24th (Friday), 2024</li>
            <li>Result announcement: May 31st (Friday), 2024 </li>
            <li>Paper submission deadline: June 17th (Monday), 2024</li>
            <li>Notification of acceptance: June 28th (Friday), 2024 </li>
            <li>Camera-ready paper due: July 8th (Monday), 2024 </li>
            <li>Workshop dates: August 15th–16th, 2024 </li>
          </ul> 

         <h3>Organizers</h3>

        <p><a href="">Joel Chan (University of Maryland)</a></p>
        <p><a href="">Matthew Akamatsu (University of Washington)</a></p>
        <p><a href="">Aakanksha Naik (Allen Institute for AI)</a></p>


        <!-- mup ========================================================= -->

    <!--    <h2 id="mup"><a href="https://github.com/allenai/mup">MuP23: Multi Perspective Scientific Document Summarization</a></h2>
        <p>
          Generating summaries of scientific documents is known to be a challenging task. Majority of existing work in summarization assumes only one single best gold summary for each given document. Having only one gold summary negatively impacts our ability to evaluate the quality of summarization systems as writing summaries is a subjective activity. At the same time, annotating multiple gold summaries for scientific documents can be extremely expensive as it requires domain experts to read and understand long scientific documents. This shared task will be its second iteration, following the success of MuP 2022, and will enable exploring methods for generating multi-perspective summaries. The training and evaluation dataset consists of data from scientific peer reviews to capture diverse perspectives from the reader's point of view.
        </p>

        <!-- <ol class="refs" id="refs-longsumm">
          <li>Iz Beltagy, Arman Cohan, Guy Feigenblat, Dayne Fre-itag, Tirthankar Ghosal, Keith Hall, Drahomira Herrmannova, Petr Knoth, Kyle Lo, Philipp Mayr, Robert M. Patton, Michal Shmueli-Scheuer, Anita de Waard, Kuansan Wang, and Lucy Lu Wang. (2021). "<a href="https://aclanthology.org/2021.sdp-1.0/">Proceedings of the Second Workshop on Scholarly Document Processing</a>." Association for Computational Linguistics.</li>
        </ol> -->
          

         <!-- <p>
          Please join our task <a href="https://forms.gle/K2UECKvmghzDHUpo7">here</a>.
         </p> -->
  <!--       <p>
          Please refer to our <a href="https://github.com/allenai/mup">MuP task page</a> for more details.
        </p>
        <h3>Organizers</h3>

        <p>Guy Feigenblat, Piiano, Israel</p>

        <p><a href="https://researcher.watson.ibm.com/researcher/view.php?person=il-SHMUELI">Michal Shmueli-Scheuer</a>, IBM Research AI, Haifa Research Lab, Israel</p>

        <p><a href="http://armancohan.com/">Arman Cohan</a>, Allen Institute for AI, Seattle, USA</p>

        <p><a href="https://elitr.eu/tirthankar-ghosal/">Tirthankar Ghosal</a>, Charles University, Czech Republic</p>

        <hr class="featurette-divider">

        <!-- svident ======================================================== -->

    <!--    <h2 id="svident">SV-Ident23: Survey Variable Identification in Social Science</h2>

        <p>
          For the SV-Ident shared task, we focus on identifying concepts in scientific literature, namely in the social science domain. The task itself is oriented toward solving a real-world challenge for researchers. We build and extend on the first SV-Ident 2022 shared task <a href="refs-svident">[1]</a> by releasing a cleaned version of the data (Data is available via https://vadis-project.github.io/sv-ident-sdp2022/). Furthermore, we make the shared task more accessible to broader audiences by including new tasks. We plan to split the shared task into multiple binary sentence classification and search tasks. For search, we propose sentence recommendation, which deals with finding relevant sentences to a given input, and passage retrieval, which is the inverse task: given an input sentence, a system should retrieve relevant passages. To better understand model rationale, we may also include a task on explainability.
        </p>

        <p>
          We split the task into two sub-tasks: a) variable detection and b) variable disambiguation. Variable detection deals with identifying
          whether a sentence contains a variable mention or not, whereas variable disambiguation focuses on identifying which variable from the
          vocabulary is specifically mentioned in a certain sentence.
        </p>

        <p>
          This task is organized by the VAriable Detection, Interlinking and Summarization (VADIS) project.
        </p>

         <p>
          Link to the SV-Ident 2022 page (more info to come): <a href="https://vadis-project.github.io/sv-ident-sdp2022/">https://vadis-project.github.io/sv-ident-sdp2022/</a>
        </p>

        <ol class="refs" id="refs-svident">
          <li>Tornike Tsereteli, Yavuz Selim Kartal, Simone Paolo, Ponzetto, Andrea Zielinski, Kai Eckert, and Philipp Mayr. 2022"<a href="https://aclanthology.org/2022.sdp-1.29/">Overview of the SV-Ident 2022 Shared Task on Survey Variable Identification in Social Science Publications</a>
          </li>
        </ol>

        <h3>Organizers</h3>

        <p><a href="https://www.uni-mannheim.de/dws/people/professors/prof-dr-simone-paolo-ponzetto/">Simone Paolo Ponzetto</a>, University of Mannheim</p>

        <p><a href="https://www.isi.fraunhofer.de/en/competence-center/innovations-wissensoekonomie/mitarbeiter/zielinski.html">Andrea Zielinski</a>, Fraunhofer ISI</p>

        <p><a href="https://www.torniketsereteli.com/">Tornike Tsereteli</a>, University of Stuttgart</p>

        <p><a href="https://www.linkedin.com/in/yavuz-selim-kartal-4924bb61/">Yavuz Selim Kartal</a>, GESIS</p>

        <p><a href="https://www.gesis.org/en/institute/staff/person/philipp.mayr">Philipp Mayr</a>, GESIS</p>

        <p><a href="">Kai Eckert</a></p>

        <hr class="featurette-divider">

        <!-- graph ======================================================== -->

    <!--    <h2 id="graph">Scholarly Knowledge Graph Generation</h2>

        <p>
          With the demise of the widely used Microsoft Academic Graph (MAG) <a href="refs-skgg">[1]</a>, <a href="refs-skgg">[2]</a> at the end of 2021, the scholarly document processing community faces a pressing need to replace MAG with an open source community supported service. A number of challenging data processing tasks are needed to create a comprehensive scholarly graph, i.e., a graph of entities including research papers, authors, research organisations, and research themes. This shared task will evaluate three key sub-tasks:
        </p>

        <ol>
          <li>document deduplication, identifying and linking different versions of the same paper,</li>
          <li>extracting research themes, and</li>
          <li>affiliation mining, linking papers to the organisations that produced them.</li>
        </ol>

        <p>
          Test and evaluation data will be supplied by the CORE aggregator <a href="refs-skgg">[3]</a>.
        </p>

        <ol class="refs" id="refs-skgg">
          <li>Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Yuxiao Dong, and Anshul Kanakia. (2020). "<a href="https://direct.mit.edu/qss/article/1/1/396/15572/Microsoft-Academic-Graph-When-experts-are-not">Microsoft academic graph: When experts are not enough</a>." Quantitative Science Studies. MIT Press Direct.</li>
          <li>Drahomira Herrmannova and Petr Knoth. (2016). "<a href="https://dlib.org/dlib/september16/herrmannova/09herrmannova.print.html">An analysis of the microsoft academic graph</a>." D-Lib Magazine.</li>
          <li>Petr Knoth and Zdenek Zdrahal. (2012). "<a href="http://www.dlib.org/dlib/november12/knoth/11knoth.print.html">Core: three access levels to underpin open access</a>." D-Lib Magazine.</li>
        </ol>

        <h3>Preregistration</h3>

        <p>
          <a href="https://forms.gle/7nduU6meseEpv9i69">Pre-register your team here</a> and we'll keep you posted with competition updates and timelines.
        </p>

        <h3>Organizers</h3>

        <p><a href="https://www.open.ac.uk/people/pk3295">Petr Knoth</a>, Open University</p>

        <p><a href="http://kmi.open.ac.uk/people/member/david-pride">David Pride</a>, Open University</p>

        <p><a href="https://www.linkedin.com/in/ronin-wu-66221226/">Ronin Wu</a>, Iris.ai</p>

        <p><a href="https://dasha.tech">Drahomira Herrmannova</a></p>

        <hr class="featurette-divider">

        <!-- ar ======================================================== -->
 <!--       <h2 id="ar">NLP for Augmented Reading Interfaces</a></h2>
        <p>
          Despite the formidable knowledge a researcher gains over the course of their career, they often still find that papers can be prohibitively difficult to read. While augmented reading interfaces have proven useful for helping scholars digest content and minimize distractions while reading <a href="refs-ar">[1]</a>, the information extraction and summarization models needed to power these interfaces currently fall short <a href="refs-ar">[2]</a>. This shared task provides real-world data and software to support development of methods for 1) symbol, term, and acronym definition, and 2) key passage highlighting
        </p>
        <!--  <p>
          Please join our task <a href="https://forms.gle/K2UECKvmghzDHUpo7">here</a>.
         </p>
         <p>
          Please refer to our <a href="https://github.com/allenai/mup">MuP task page</a> for more details.
        </p> -->

  <!--      <ol class="refs" id="refs-ar">
          <li>Andrew Head, Kyle Lo, Dongyeop Kang, Raymond Fok, Sam Skjonsberg, Daniel S. Weld, and Marti A. Hearst. (2021). "<a href="https://dl.acm.org/doi/10.1145/3411764.3445648">Augmenting Scientific Papers with Just-in-Time, Position-Sensitive Definitions of Terms and Symbols</a>." Association for Computing Machinery, New York, NY, USA.</li>
          <li>Dongyeop Kang, Andrew Head, Risham Sidhu, Kyle Lo, Daniel Weld, and Marti A. Hearst. (2020). "<a href="https://aclanthology.org/2020.sdp-1.22/">Document-Level Definition Detection in Scholarly Documents: Existing Models, Error Analyses, and Future Directions</a>."  Association for Computational Linguistics.</li>
        </ol>

        <h3>Organizers</h3>

        <p><a href="https://kyleclo.github.io/">Kyle Lo</a>, Allen Institute for AI, Seattle, USA</p>

        <p><a href="">Andrew Head</a></p>

        <p><a href="">Marti Hearst</a></p>


        <!-- SciCompare ======================================================== -->
  <!--      <h2 id="SciCompare">SciCompare</a></h2>
        <p>
          Often when reviewing literature, scientists find it necessary to compare the contents of two or more scientific papers. The goal of this pilot shared task is to encourage the development of automated systems for generating these comparisons. In this task, the inputs are two or more scientific papers and the output is a short sentence that compares them along some dimension (e.g. motivation, methods, results). The dataset for this task consists of 5K+ pairs of papers along with a comparison sentence for each. These comparison sentences are extracted from the papers' related work sections, and are decontextualized through a combination of automatic rewriting and human annotator validation. Systems will be evaluated by comparing generations to reference comparisons (i.e. using Rouge and BERTScore) and by aligning phrases in the comparisons to phrases in the paper to ensure the comparisons are faithful to the papers.
        </p>
        <!--  <p>
          Please join our task <a href="https://forms.gle/K2UECKvmghzDHUpo7">here</a>.
         </p>
         <p>
          Please refer to our <a href="https://github.com/allenai/mup">MuP task page</a> for more details.
        </p> -->

       <!--  <ol class="refs" id="refs-ar">
          <li>Andrew Head, Kyle Lo, Dongyeop Kang, Raymond Fok, Sam Skjonsberg, Daniel S. Weld, and Marti A. Hearst. (2021). "<a href="https://dl.acm.org/doi/10.1145/3411764.3445648">Augmenting Scientific Papers with Just-in-Time, Position-Sensitive Definitions of Terms and Symbols</a>." Association for Computing Machinery, New York, NY, USA.</li>
          <li>Dongyeop Kang, Andrew Head, Risham Sidhu, Kyle Lo, Daniel Weld, and Marti A. Hearst. (2020). "<a href="https://aclanthology.org/2020.sdp-1.22/">Document-Level Definition Detection in Scholarly Documents: Existing Models, Error Analyses, and Future Directions</a>."  Association for Computational Linguistics.</li>
        </ol> -->

   <!--     <h3>Organizers</h3>

        <p><a href="https://kyleclo.github.io/">Kyle Lo</a>, Allen Institute for AI, Seattle, USA</p>

        <p><a href="http://armancohan.com/">Arman Cohan</a>, Allen Institute for AI, Seattle, USA</p>

        <p><a href="">Benjamin Newmann</a></p>
        

        <!-- IMPORTANT DATES ========================================================= -->

        <!-- <h2 id="register">Registration</h2>

        <p>
          To register for participation in the shared tasks, please use <a href="https://docs.google.com/forms/d/e/1FAIpQLScfHzByrog-k299qBuCp3SbPWcb905_kmOWMvHpDH57VLpVrg/viewform">this registration form</a>.
        </p>

        <p>TBA</p>

        <hr class="featurette-divider"> -->

        <!-- IMPORTANT DATES ========================================================= -->

        <!-- <h2 id="dates">Important Dates</h2>

        <p>
          Please consult the <a href="index.html">SDP Workshop website</a> for official dates for the workshop. All submission deadlines are 11:59 PM AoE (Anywhere on Earth) Time Zone (UTC-12).
        </p>

        <table class="table table-striped">
          <thead>
            <tr>
              <th scope="col">Event</th>
              <th scope="col">Date</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Training Set Release</td>
              <td>Feb 15, 2020. An additional development set will be made available closer to the test set release date</td>
            </tr>
            <tr>
              <td>Deadline for Registration</td>
              <td> April 30 (remains open till evaluation window starts)<br /></td>
            </tr>
            <tr>
              <td>Test Set Release (Blind)</td>
              <td><del>July 1, 2020</del> July 15, 2020</td>
            </tr>
            <tr>
              <td>System Runs Due</td>
              <td><del>August 1, 2020</del> Aug 15, 2020 </td>
            </tr>
            <tr>
              <td>Preliminary System Reports Due in SoftConf</td>
              <td>August 16, 2020</td>
            </tr>
            <tr>
              <td>Camera-Ready Contributions Due in SoftConf</td>
              <td><del>August 31, 2020</del> Oct 10, 2020</td>
            </tr>
            <tr>
              <td>Participant Presentations at SDP 2020</td>
              <td><del>Nov 12</del> Nov 19, 2020</td>
            </tr>
          </tbody>
        </table>

        <hr class="featurette-divider"> -->

      </div>
    </div>

    <!-- FOOTER ========================================== -->

    <hr><br />

    <footer>
      <div class="footer-wrapper">
        <div class="footer-left">
          <p>Contact: <a href="mailto:sdproc2024@googlegroups.com">sdproc2024@googlegroups.com</a></p>
          <p>Sign up for updates: <a href="https://groups.google.com/g/sdproc-updates">https://groups.google.com/g/sdproc-updates</a></p>
          <p>Follow us: <a href="https://twitter.com/SDPWorkshop">https://twitter.com/SDPWorkshop</a></p>
        </div>
        <div class="footer-right">
          <a href="#">Back to top</a>
        </div>
    </footer>

  </div>

  <!-- Bootstrap core JavaScript ================================================== -->
  <script src="./dist/js/bootstrap.min.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</body>

</html>
